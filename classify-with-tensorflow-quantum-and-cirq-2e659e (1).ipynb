{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Classification on Fashion MNIST with TensorFlow-Quantum and Cirq","metadata":{"id":"ul073WDztsNU"}},{"cell_type":"markdown","source":"## About the Dataset and QML","metadata":{"id":"FDtXZb18m0Jq"}},{"cell_type":"markdown","source":"The original MNIST dataset contains a lot of handwritten digits. People from AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset they would try on. ***“If it doesn’t work on MNIST, it won’t work at all”***, they said. ***“Well, if it does work on MNIST, it may still fail on others.”*** Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset to benchmark machine learning algorithms, as it shares the same image size and the structure of training and testing splits.","metadata":{"id":"ecq9vXs7opLM"}},{"cell_type":"markdown","source":"We shall perform QML on Fashion MNIST dataset using TensorFLow Quantum and Cirq. \n\n[TensorFlow-Quantum](https://www.tensorflow.org/quantum/tutorials) is a great place to start learning QML and get into this amazing field. TensorFlow Quantum (TFQ) is a quantum machine learning library for rapid prototyping of hybrid quantum-classical ML models.TensorFlow Quantum focuses on quantum data and building hybrid quantum-classical models. It integrates quantum computing algorithms and logic designed in Cirq, and provides quantum computing primitives compatible with existing TensorFlow APIs, along with high-performance quantum circuit simulators. \n\n[Cirq](https://quantumai.google/cirq) is a Python software library for writing, manipulating, and optimizing quantum circuits, and then running them on quantum computers and quantum simulators. Cirq provides useful abstractions for dealing with today’s noisy intermediate-scale quantum computers, where details of the hardware are vital to achieving state-of-the-art results.","metadata":{"id":"TBbNH7k6qSgt"}},{"cell_type":"markdown","source":"Today's(NISQ Era) Quantum Computer are not very powerful and have various limitations. Also, the field of Quantum Machine Learning is currently evolving. To keep things simple, we will modify the Fashion MNIST dataset by making classification on only two classes - Sandal and Ankle boot. The reason to choose these classes is that they are similar to each other and therefore, it ascertains that the classification problem doesn't become very easy. The image shape in the provided dataset is (28,28), but we need to downscale the images to classify them using QML due to the hardware restrictions. We will downscale the images so that they have the shape (4,4).","metadata":{"id":"AOCdlEjxKoRN"}},{"cell_type":"markdown","source":"Number of Images in the Train Dataset - 10200\n\nNumber of Images in the Validation Dataset - 1800\n\nNumber of Images in the Test Dataset - 2000\n\nSize of each Image - (2,2)\n\nType of Image - Grayscale Image\n\nNumber of Labels - 2\n\n\n~~~\nLabel\tDescription\n5\t    Sandal\n9\t    Ankle boot\n~~~","metadata":{"id":"1mB2jAsznFZK"}},{"cell_type":"markdown","source":"## Installing required packages","metadata":{"id":"_Xi8mJUptn42"}},{"cell_type":"code","source":"# installing TensorFLow Version 2.3.1\nfrom IPython.display import clear_output\n!pip install -q tensorflow==2.3.1\nclear_output()","metadata":{"id":"Xj9X94SHs7_o","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# install tensorflow quantum\n!pip install -q tensorflow_quantum\nclear_output()","metadata":{"id":"jEFDCf90oOwN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#install cirq\n!pip install cirq\nclear_output()","metadata":{"id":"Kr4kAs3ipWYN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the dataset and required packages","metadata":{"id":"4E3JNaVwu-SX"}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Data Processing tools\nimport numpy as np\nfrom sklearn.model_selection import train_test_split \n\n# QML tools\nimport tensorflow_quantum as tfq\nimport cirq\nimport sympy\n\n# Visualization Tools\nfrom cirq.contrib.svg import SVGCircuit\nimport matplotlib.pyplot as plt","metadata":{"id":"otBjLV4ovAqm","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets print the version of cirq and tfq that we will use\nprint(\"We are using the TensorFlow-Quantum version {}\".format(tfq.__version__))\nprint(\"We are using the Cirq version {}\".format(cirq.__version__))","metadata":{"id":"MxejhA8Iumpu","outputId":"d5e04292-fb96-40c9-cb98-1a1f1724601d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the Fashion MNIST dataset from keras\nfrom tensorflow.keras.datasets import fashion_mnist as dataset","metadata":{"id":"nvAb6_0xnBRX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = dataset.load_data()","metadata":{"id":"7_xF9rR-rNFz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The shape of the X_train is {}\".format( X_train.shape))\nprint(\"The shape of the y_train is {}\".format(y_train.shape))\nprint(\"The shape of the X_test is {}\".format(X_test.shape))\nprint(\"The shape of the y_test is {}\".format(y_test.shape))","metadata":{"id":"kFlj0AvvrqIW","outputId":"8121f0be-6284-4608-e0b6-29703f49cf9f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the Dataset","metadata":{"id":"jDyH0wwXwCOK"}},{"cell_type":"code","source":"def filter_data(x, y):\n  \"\"\"\n  Helper Function to filter the dataset\n  \"\"\"\n  #filter the data using labels\n  keep = (y == 5) | (y == 9)\n  x, y = x[keep], y[keep]\n\n  # convert labels to boolean\n  # y = True if y==5\n  # y = False if y==9\n  y = y == 5\n  return x,y","metadata":{"id":"3z2lgVw1wELa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filter the train set\nX_train, y_train = filter_data(X_train, y_train)\n\n#Filter the test_set\nX_test, y_test = filter_data(X_test, y_test)","metadata":{"id":"jQHzPIhA6og7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's have a look at the shapes of train and test data\nprint(\"The shape of the X_train is {}\".format( X_train.shape))\nprint(\"The shape of the y_train is {}\".format(y_train.shape))\nprint(\"The shape of the X_test is {}\".format(X_test.shape))\nprint(\"The shape of the y_test is {}\".format(y_test.shape))","metadata":{"id":"DU7rvKtu-CSu","outputId":"b258ec37-a770-4bd2-e8bb-7d1be423d2b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's have a look at the first image from our X_train and the \n# corresponding label from y_train\nprint(\"The First Image has the label {}\".format(y_train[0]))\nplt.imshow(X_train[0])\nplt.colorbar()\nplt.title('Visualization of the Dataset')\nplt.show()","metadata":{"id":"Ymg4FvbDsmbO","outputId":"1cef323b-481a-4e2e-ad05-54a4958be3a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the colorbar in the above visualization, it is clear that we have grayscale images in the dataset and hence their values range from 0 to 255. However, we would like to scale these pixel values in our dataset so that the values range from 0 to 1. This will help us to converge our CNN training faster","metadata":{"id":"e7QO_qj5uTN9"}},{"cell_type":"code","source":"#Normalizing the train and test image data\nX_train = X_train/255.0\nX_test = X_test/ 255.0","metadata":{"id":"e3qqMcOFvr5b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's again have a look at the first image from our X_train and\n#see if we have successfully normalized the datasets\nplt.imshow(X_train[0])\nplt.colorbar()\nplt.title('Visualization of the Dataset')\nplt.show()","metadata":{"id":"Bevkendhuzsq","outputId":"d1cf7cbf-a8e7-4e29-eaf9-88cfa83caa74","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Before proceeding, we need to reshape our images in the dataset\nX_train = X_train.reshape(X_train.shape[0], *(28,28,1))\nX_test = X_test.reshape(X_test.shape[0], *(28,28,1))","metadata":{"id":"Cfgtl9kUD9H5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Downscaling the images\nX_train = tf.image.resize(X_train, (2,2)).numpy()\nX_test = tf.image.resize(X_test, (2,2)).numpy()\n","metadata":{"id":"cvBKLXbc_cZg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's again have a look at the first image from our resized X_train\nplt.imshow(X_train[0,:,:,0])\nplt.colorbar()\nplt.title('Visualization of the Resized Dataset')\nplt.show()","metadata":{"id":"iKWbEihSJBX_","outputId":"d1f35533-1c91-4ac8-8a5f-c7ba607b67c6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting the training fdataset into train and validation datasets\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.15, random_state=0)","metadata":{"id":"-yiNywWqP610","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The shape of the X_train is {}\".format(X_train.shape))\nprint(\"The shape of the y_train is {}\".format(y_train.shape))\nprint(\"The shape of the X_valid is {}\".format(X_valid.shape))\nprint(\"The shape of the y_valid is {}\".format(y_valid.shape))","metadata":{"id":"jy57uzOT-LvY","outputId":"8e655d0a-b97a-4c14-da72-185d4c16c796","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Encoding","metadata":{"id":"hDTiCqXpPQ4x"}},{"cell_type":"markdown","source":"Steps involved in Data Encoding:\n\n* Processing pixel values for binary encoding\n\n* Converting Cirq Circuits to tfq tensors","metadata":{"id":"j54vI9ydZUfc"}},{"cell_type":"markdown","source":"**Step 1: Processing Pixel Values for Binary Encoding**","metadata":{"id":"dJCkl4_tfERJ"}},{"cell_type":"code","source":"# FLattening the images\nX_train = X_train.reshape(X_train.shape[0], *(1,4,1))\nX_valid = X_valid.reshape(X_valid.shape[0], *(1,4,1))\nX_test = X_test.reshape(X_test.shape[0], *(1,4,1))","metadata":{"id":"mhxgJsxhfuzZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Processing X_train","metadata":{"id":"DtYwPoLPd6iH"}},{"cell_type":"code","source":"#Let's have a look on the first example\nprint(X_train[0])","metadata":{"id":"FuJABwN8eGNc","outputId":"ba9c48cd-51f2-4cc7-8851-3bebebcfff35","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef binary_encode(X,threshold=0.5):\n  \"\"\"\n  Encodes the given datset to use binary encoding\n\n  Parameters:\n  X(array) : Image data to be processed for encoding\n  threshold(float): Threshold for binary encoding, 0.5 by default\n\n  Returns:\n  encoded_images(array): Binary encoded Image Data\n\n  \"\"\" \n  encoded_images = list()\n  for image in X:\n    # pixel value is 1 if it's greater than threshold or else zero\n    encoded_image = [1 if j>threshold else 0 for j in image[0]]\n    encoded_images.append(encoded_image)\n  return np.array(encoded_images)","metadata":{"id":"rIzIktKfhXRi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = binary_encode(X_train)","metadata":{"id":"eymmTOimcxSN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, Let's have a look on the first example again\nprint(X_train[0])","metadata":{"id":"sESCMm_xc47k","outputId":"47746dc2-a491-4551-c314-97b1f7f2c056","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The shape of the X_train is {}\".format(X_train.shape))","metadata":{"id":"PCv2dDsmfMOM","outputId":"fac9a3ec-4b0a-4cd2-923f-c17b937ff14d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_circuit_from_image(encoded_image):\n  \"\"\"\n  Returns a circuit for given encoded image\n\n  Parameters:\n  encoded_image (array): Encoded Image\n\n  Returns:\n  circuit (cirq.Circuit object): cirq circuit\n  \"\"\"\n  qubits = cirq.GridQubit.rect(2,2)\n  circuit = cirq.Circuit()\n  for i, pixel in enumerate(encoded_image):\n    if pixel:\n      circuit.append(cirq.X(qubits[i]))\n  return circuit","metadata":{"id":"0P6g8CypTktk","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = [create_circuit_from_image(encoded_image) for encoded_image in X_train]","metadata":{"id":"sTNIeH-2WA8-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's have a look at the circuit for the first image\nprint(X_train[0])","metadata":{"id":"g8kkNTVvWiBm","outputId":"f0da20e0-7714-441c-ac66-76af44202cdc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Recall that the values for the first image were 0,0,1,1. This implies that we should apply X or NOT gate the last two qubuts since all the qubits are intially in the 0 states. Applying a X gate will change this state from zero to one. Therefore, we shall apply X Gate on the last two qubits. We have initialized the four qubits in a rectangular grid. Therefore, the initialized qubits are (0,0), (0,1), (1,0) and (1,1). In the above circuit diagram, note that we have a X gate on the qubits (1,0) and (1,1) which are the last two qubits. Hence, we have successfully created circuit for our image. ","metadata":{"id":"fUaCe4BLXM3m"}},{"cell_type":"markdown","source":"**Step 2: Converting Cirq Circuits to tfq Tensors**","metadata":{"id":"RCU6S7WhZ3Ct"}},{"cell_type":"code","source":"X_train_tfq = tfq.convert_to_tensor(X_train)","metadata":{"id":"MM-yJnfcZ2VO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Processing X_valid and X_test","metadata":{"id":"nRdvapAEalmd"}},{"cell_type":"code","source":"X_valid = binary_encode(X_valid)\nX_test = binary_encode(X_test)","metadata":{"id":"LbofYr2faX9J","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid = [create_circuit_from_image(encoded_image) for encoded_image in X_valid]\nX_test = [create_circuit_from_image(encoded_image) for encoded_image in X_test]","metadata":{"id":"V5HoVBnXbLeP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid_tfq = tfq.convert_to_tensor(X_valid)\nX_test_tfq = tfq.convert_to_tensor(X_test)","metadata":{"id":"YsQE1fdFbcV0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quantum Neural Network","metadata":{"id":"2Oo5q95fPT6n"}},{"cell_type":"markdown","source":"### Build the QNN","metadata":{"id":"RM86REiy7ChU"}},{"cell_type":"markdown","source":"Building the Quantum Neural Network involves two steps\n\n* build a class that adds gates layer by layer\n\n* define the QNN using the class from the above step","metadata":{"id":"m_lrpb-TcCJG"}},{"cell_type":"code","source":"class QNN():\n    def __init__(self, data_qubits, readout):\n      self.data_qubits = data_qubits\n      self.readout = readout\n\n    def add_singleQubit_gate(self,circuit, gate, qubit_index):\n      \"\"\"\n      Adds single qubit gate to the circuit\n      Parameters:\n      circuit(cirq.Circuit object): Cirq circuit\n      gate(cirq gate): gate to append to the circuit\n      qubits(list): index of qubits to apply the gate \n      Returns:\n      None\n      \"\"\"\n      for index in qubit_index:\n        circuit.append(gate(self.data_qubits[index]))\n\n    def add_twoQubit_gate(self,circuit, gate, qubit_index):\n      \"\"\"\n      Adds two qubit gate to the circuit\n      Parameters:\n      circuit(cirq.Circuit object): Cirq circuit\n      gate(cirq gate): gate to append to the circuit\n      qubits(list): index of qubits to apply the gate\n      Returns:\n      None\n      \"\"\"\n      if len(qubit_index)!=2:\n        raise Exception(\"The length of the list of indices passed for two qubit \\\n        gate operations must be equal to two\")\n      circuit.append(gate(self.data_qubits[qubit_index[0]], self.data_qubits[qubit_index[1]]))\n\n    def add_layer(self, circuit, gate, symbol_gate):\n      \"\"\"\n      Adds New Gates/Layers to the Circuit\n      Parameters:\n      circuit(cirq.Circuit object): Cirq circuit\n      gate(cirq gate): gate to append to the circuit\n      symbol_gate(string): symbol for the gate\n      Returns:\n      None\n      \"\"\"\n      for i, qubit in enumerate(self.data_qubits):\n        symbol = sympy.Symbol(symbol_gate+ '-' + str(i))\n        circuit.append(gate(qubit, self.readout)**symbol)\n","metadata":{"id":"DycQEj54JrLW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_qnn():\n    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n    data_qubits = cirq.GridQubit.rect(2,2)  # a 4x4 grid.\n    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n    circuit = cirq.Circuit()\n\n    # Prepare the readout qubit.\n    circuit.append(cirq.X(readout))\n    circuit.append(cirq.H(readout))\n\n    qnn = QNN(\n        data_qubits = data_qubits,\n        readout=readout)\n    \n    \"\"\"\n    # Though we don't use single and double Qubit Gates in our Circuit, we provide \n    # the methods \"add_singleQubit_gate\" and \"add_twoQubit_gate\" for our Class QNN\n    # that can be used to add Single and Double Qubit Gates respectively.\n    # An exmaple is shown below:\n\n    #Add Hadamard Gates\n    qnn.add_singleQubit_gate(circuit, cirq.H, [0,1,2,3])\n\n    #Add CNOT gates\n    qnn.add_twoQubit_gate(circuit, cirq.CNOT, [0, 1])\n    qnn.add_twoQubit_gate(circuit, cirq.CNOT, [2, 3])\n    \"\"\"\n\n    # Add the ising coupling XX gate\n    qnn.add_layer(circuit, cirq.XX, \"xx\")\n    qnn.add_layer(circuit, cirq.ZZ, \"zz\")\n\n    # Finally, prepare the readout qubit.\n    circuit.append(cirq.H(readout))\n\n    return circuit, cirq.Z(readout)","metadata":{"id":"sQxpS03x1VKT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qmodel, model_readout = create_qnn()","metadata":{"id":"bkW8IUUj3Ats","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's have a look at our Qauntum Circuit that will perform the classification\nSVGCircuit(qmodel)","metadata":{"id":"B8SigYUiGE0g","outputId":"6846e686-5f70-46d2-881a-06a582d66f42","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n                             \n    # The input is the data-circuit, encoded as a tf.string\n    tf.keras.layers.Input(shape=(), dtype=tf.string),\n\n    \n    # The PQC stands for Paramaterized Quantum Circuit\n    # This returns the expectation value\n    tfq.layers.PQC(qmodel, model_readout),\n])","metadata":{"id":"fi0bmTsp3VHB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To use Hinge Loss, we convert the labels to 1 and -1\ny_train_h = np.array([1 if i==1 else -1 for i in y_train ])\ny_valid_h = np.array([1 if i==1 else -1 for i in y_valid ])\ny_test_h = np.array([1 if i==1 else -1 for i in y_test ])","metadata":{"id":"-Es8_ATXDFL6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's have a look at the first label from the training dataset\nprint(y_train_h[0])","metadata":{"id":"tueGJaAWOtWf","outputId":"8389a3a7-5194-4f29-b143-b9abb13bad2a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the custom Hinge Accuracy\ndef hinge_accuracy(y_true, y_pred):\n    y_true = tf.squeeze(y_true) > 0.0\n    y_pred = tf.squeeze(y_pred) > 0.0\n    result = tf.cast(y_true == y_pred, tf.float32)\n\n    return tf.reduce_mean(result)","metadata":{"id":"Ifriy2HyoI-O","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the QNN","metadata":{"id":"WUewMTq87Hl3"}},{"cell_type":"code","source":"model.compile(\n    loss=tf.keras.losses.Hinge(),\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    metrics=[hinge_accuracy])","metadata":{"id":"klSZErcc3kAz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qnn_history = model.fit(\n      X_train_tfq, y_train_h,\n      batch_size=64,\n      epochs=10,\n      verbose=1,\n      validation_data=(X_valid_tfq, y_valid_h))","metadata":{"id":"nO3eEigt4HgT","outputId":"4d4dceb7-98e7-4e65-e46c-c58f04bf7199","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test_tfq, y_test_h)","metadata":{"id":"WBY-ECy54qyC","outputId":"d53e8a69-88d1-48b2-87b0-318bd85e58d6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize the Results","metadata":{"id":"dw6i8L1RQIUI"}},{"cell_type":"code","source":"# Visualize Accuracy\nplt.plot(qnn_history.history['hinge_accuracy'])\nplt.plot(qnn_history.history['val_hinge_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['train','test'],loc=\"best\")\nplt.show()","metadata":{"id":"NK6Aw5LdOiWh","outputId":"7b365ca6-0d5a-4a23-b049-4a505697b079","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize Loss\nplt.plot(qnn_history.history['loss'])\nplt.plot(qnn_history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['train','test'],loc=\"best\")\nplt.show()","metadata":{"id":"9IbgVjZQRAue","outputId":"aeb4d475-dfe0-440e-a10e-2744a7e2ffbe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save The Model Weights","metadata":{"id":"nxx-qCBIRcih"}},{"cell_type":"code","source":"#Saving the weights\nmodel.save_weights('/content/sample_data/QModelWeights')","metadata":{"id":"Sh4pazWbRjR_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Refernces","metadata":{"id":"iXLmchzKapew"}},{"cell_type":"markdown","source":"* https://www.tensorflow.org/quantum/tutorials/mnist\n* https://quantumai.google/cirq/tutorials\n* [Paper by Farhi et al.](https://arxiv.org/pdf/1802.06002.pdf)\n* [Paper by Dmitri Maslov](https://www.google.com/url?sa=t&source=web&rct=j&url=https://arxiv.org/pdf/1603.07678&ved=2ahUKEwi86KbBlfvuAhUmzDgGHfteCIsQFjAJegQIHhAC&usg=AOvVaw04beRgWLMZhYBV6GpyygHF)","metadata":{"id":"_fx9p7mparf3"}}]}